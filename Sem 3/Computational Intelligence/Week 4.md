# Problem 1

Create a dataset for spam email detection with ten binary features. Train MLP to detect emails
spam or not using squared error loss function and binary cross entropy loss function with back
propagation gradient descent.
1. After each backward pass, print gradients of each layer
2. Compare the convergence capability of the two loss functions
3. Visualize the loss reduction over iterations
4. Show the significance of varying number of hidden layers and number of neurons in
the hidden layers
